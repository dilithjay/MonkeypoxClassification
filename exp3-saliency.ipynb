{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['acne', 'chickenpox', 'cowpox', 'measles', 'melanoma', 'monkeypox', 'normal', 'other', 'smallpox']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions used to generate saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saliency_bin(model, image):\n",
    "    scores = model(image.unsqueeze(dim=0)).squeeze()\n",
    "    scores.backward()\n",
    "\n",
    "    saliency, _ = torch.max(image.grad.data.abs(), dim=1)\n",
    "    saliency = saliency.reshape(224, 224)\n",
    "    return saliency\n",
    "\n",
    "def get_saliency_multi(model, image):\n",
    "    scores = model(image.unsqueeze(dim=0))\n",
    "    output_idx = 5\n",
    "    output_max = scores[0, output_idx]\n",
    "    output_max.backward()\n",
    "\n",
    "    saliency, _ = torch.max(image.grad.data.abs(), dim=0)\n",
    "    saliency = saliency.reshape(224, 224)\n",
    "    return saliency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = (\"multiclass\", \"binary\", \"binary_2_class\")[0]\n",
    "if exp == 'multiclass':\n",
    "    model_fc = torch.nn.Linear(2048, len(classes))\n",
    "    model_path = sorted(glob(\"models/*multi*.pt\"))[-1]\n",
    "    saliency_func = get_saliency_multi\n",
    "elif exp == \"binary\":\n",
    "    model_fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(2048, 1),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "    model_path = sorted(glob(\"models/*bin_*.pt\"))[-1]\n",
    "    saliency_func = get_saliency_bin\n",
    "elif exp == \"binary_2_class\":\n",
    "    model_fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(2048, 2),\n",
    "        torch.nn.Softmax(dim=1)\n",
    "    )\n",
    "    model_path = sorted(glob(\"models/*bin2c_*.pt\"))[-1]\n",
    "    saliency_func = get_saliency_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model.fc = model_fc\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing using Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    transforms.Resize((224, 224)),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting disease class and extracting Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = sorted(glob(\"/home/dilith/Projects/monkeypox/data/combined/monkeypox/*\"))[5]\n",
    "print(image_path)\n",
    "# image_path = \"/home/dilith/Projects/monkeypox/data/combined/monkeypox/Moneypox_3.jpg\"\n",
    "\n",
    "pil_image = Image.open(image_path)\n",
    "image = transform(pil_image)\n",
    "image = image.to(device)\n",
    "image.requires_grad_()\n",
    "pil_image = pil_image.resize((224, 224))\n",
    "\n",
    "disease = os.path.basename(os.path.dirname(image_path))\n",
    "saliency = saliency_func(model, image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(pil_image))\n",
    "plt.imshow(saliency.cpu(), alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(np.asarray(pil_image))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 14:28:56) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e60a13762b311d75094e19903d9f763963a5a049301dac08add2508c5be7c1e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
